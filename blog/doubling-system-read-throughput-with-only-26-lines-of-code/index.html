<!DOCTYPE html>
<html lang="en"><head>
<meta name="robots" content="noindex"><meta charset="utf-8"/><meta content="IE=edge" http-equiv="X-UA-Compatible"/><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no" name="viewport"/>
<script>
window.ga =
    window.ga ||
    function() {
        ;(ga.q = ga.q || []).push(arguments)
    }
ga.l = +new Date()
ga('create', 'UA-99991864-4', 'auto')
ga('send', 'pageview')
</script>
<script async="" src="https://download.pingcap.com/js/ga-analytics.js"></script>
<link href="https://download.pingcap.com/style/github-markdown.css" rel="stylesheet"/>
<link href="/css/doc.css" rel="stylesheet"/>
<title>Doubling System Read Throughput with Only 26 Lines of Code | TiDB</title><link href="/images/favicon.ico" rel="icon" type="image/x-icon"/>
<link href="/images/favicon.ico" rel="shortcut icon" type="image/x-icon"/>
<link href="/images/apple-touch-icon.png" rel="apple-touch-icon"/>
<meta content="The Follower Read feature lets any follower replica in a Region serve a read request under the premise of strongly consistent reads. It reduces the load on the Raft leader and improves the read throughput of the TiDB cluster. Read this post to learn more." name="description"/>
<meta content="noodp" name="robots"/>
<meta content="TiDB, MySQL, HTAP, Open Source, Cloud-Native, NewSQL, Aurora Alternative" name="keywords"/>
<meta content="en_US" property="og:locale"/>
<meta content="website" property="og:type"/>
<meta content="Doubling System Read Throughput with Only 26 Lines of Code | TiDB" property="og:title"/>
<meta content="The Follower Read feature lets any follower replica in a Region serve a read request under the premise of strongly consistent reads. It reduces the load on the Raft leader and improves the read throughput of the TiDB cluster. Read this post to learn more." property="og:description"/>
<meta content="https://pingcap.com/blog/doubling-system-read-throughput-with-only-26-lines-of-code/" property="og:url"/>
<meta content="MySQL at Scale. No more manual sharding" property="og:site_name"/>
<meta content="/images/blog/follower-read-load-balancing-consistent-read.png" property="og:image"/>
<meta content="/images/blog/follower-read-load-balancing-consistent-read.png" property="og:image:secure_url"/><meta content="summary_large_image" name="twitter:card"/>
<meta content="1200" name="og:image:width"/>
<meta content="600" name="og:image:height"/><meta content="The Follower Read feature lets any follower replica in a Region serve a read request under the premise of strongly consistent reads. It reduces the load on the Raft leader and improves the read throughput of the TiDB cluster. Read this post to learn more." name="twitter:description"/>
<meta content="Doubling System Read Throughput with Only 26 Lines of Code | TiDB" name="twitter:title"/>
<meta content="@pingcap" name="twitter:site"/>
<meta content="https://download.pingcap.com/images/blog/follower-read-load-balancing-consistent-read.png" name="twitter:image"/><meta content="@pingcap" name="twitter:creator"/>
<script type="application/ld+json">
{
    "@context": "http:\/\/schema.org",
    "@type": "WebSite",
    "url": "https:\/\/pingcap.com\/",
    "name": "PingCAP",
    "potentialAction": {
        "@type": "SearchAction",
        "target": "https:\/\/pingcap.com\/?s={search_term_string}",
        "query-input": "required name=search_term_string"
    }
}
</script>
<script>
    (function(){
        var bp = document.createElement('script');
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
<script async="" src="https://accounts.pingcap.com/static/pingcap_sso/js/track.beta.js" type="text/javascript"></script>
<link as="font" crossorigin="anonymous" href="https://download.pingcap.com/fonts/lato/lato-regular-webfont.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://download.pingcap.com/fonts/lato/lato-regular-webfont.woff" rel="preload" type="font/woff"/>
<link as="font" crossorigin="anonymous" href="https://download.pingcap.com/fonts/lato/lato-regular-webfont.ttf" rel="preload" type="font/ttf"/>
<link as="font" crossorigin="anonymous" href="https://download.pingcap.com/fonts/titilliumweb/titilliumweb-regular-webfont.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://download.pingcap.com/fonts/titilliumweb/titilliumweb-regular-webfont.woff" rel="preload" type="font/woff"/>
<link as="font" crossorigin="anonymous" href="https://download.pingcap.com/fonts/titilliumweb/titilliumweb-regular-webfont.ttf" rel="preload" type="font/ttf"/>
<link as="script" href="https://download.pingcap.com/js/jquery.min.js" rel="preload"/>
<link href="/css/main.css" rel="stylesheet"/>
<link href="https://download.pingcap.com/style/docsearch.min.css" rel="stylesheet"/>
<script type="text/javascript">
var trackOutboundLink = function(url) {
  var redirectTriggered = false
  ga('send', 'event', 'outbound', 'click', url, {
    hitCallback: function() {
      redirectTriggered = true
      document.location = url
    }
  })
  setTimeout(function() {
    if (!redirectTriggered) {
      document.location = url
    }
  }, 1500)
}

var trackViews = function(btn_type, event_category) {
  var event_label = btn_type
  var eventCategory = event_category
  ga('send', 'event', {
    'eventCategory': eventCategory,
    'eventAction': 'click',
    'eventLabel': event_label,
    'transport': 'beacon'
  });
}
</script>
<script>if (location.pathname === '/') {
        if (location.hostname === 'pingcap.github.io') {
            location.href = '/en/'
        }
    }</script></head> <body data-lang="en"><div id="page-content">
<header class="fixed-top" role="navigation">
<div class="container">
<a class="nav-brand" href="/en"><img alt="PingCAP" src="/images/pingcap-logo.png"/></a>
<div class="nav-wrapper">
<div class="navigation">
<ul>
<li><a class="a-en" href="https://en.pingcap.com">Cloud</a></li>
<li><a class="a-en" href="/tidb-academy">TiDB Academy</a></li>
<li class="docs-type-selector " id="docsTypeSelector">
<a class="header-doc-nav" href="#">Docs</a>
<div class="header-dropdown-menu" id="docsTypeSelectorItem">
<a class="header-dropdown-item" href="/docs/stable/">TiDB</a>
<a class="header-dropdown-item" href="/docs/tidb-in-kubernetes/stable/">TiDB in Kubernetes</a>
<a class="header-dropdown-item" href="/docs/tidb-data-migration/stable/">TiDB Data Migration (DM)</a>
</div>
</li>
<li><a class="a-en" href="/success-stories">Success
                    Stories</a></li>
<li class="sel"><a class="a-en" href="/blog">Blog</a></li>
<li><a class="link-download link-download-en" href="/download">Free Download</a></li>
</ul>
</div>
<div class="global-search">
<div class="search-wrapper">
<span class="icon-search"><svg fill="#fff" height="18" viewbox="0 0 67.125 67.125" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M23.902 0C11.01 0 .523 10.488.523 23.38c0 12.891 10.487 23.379 23.379 23.379a23.258 23.258 0 0 0 14.471-5.037l24.816 24.817c.391.391.902.586 1.414.586s1.023-.195 1.414-.586a2 2 0 0 0 0-2.828L41.293 38.985c3.721-4.142 5.989-9.613 5.989-15.605C47.282 10.488 36.794 0 23.902 0zM4.523 23.38C4.523 12.694 13.216 4 23.902 4c10.687 0 19.38 8.694 19.38 19.38 0 5.396-2.221 10.279-5.791 13.795a1.959 1.959 0 0 0-.488.349 2.003 2.003 0 0 0-.271.343C33.31 40.9 28.825 42.76 23.903 42.76c-10.686-.001-19.38-8.695-19.38-19.38z"></path><path d="M24.075 8.591c-8.25 0-14.962 6.712-14.962 14.962a2 2 0 0 0 4 0c0-6.044 4.918-10.962 10.962-10.962a2 2 0 0 0 0-4z"></path></svg></span>
<input data-lang="en" data-type="" id="search-input" name="q" placeholder="Search TiDB Docs" type="search"/>
</div>
<script>
    const inputNode = document.getElementById("search-input")

    inputNode.addEventListener('keyup', ({key}) => {
        if (key === "Enter") {
            if ($('#search-input').data('lang') == 'cn') {
                lang = 'zh'
            }

            const query = $('#search-input').val()
            if (query) {
                url = "https://docs.pingcap.com/" + (lang == 'zh' ? 'zh/' : '') + "search/?lang=" + lang + "&type=tidb&version=v4.0&q=" + query
                window.location.href = url
            }
        }
    })
</script>
</div>
</div>
<div class="nav-btn nav-slider">
<i class="material-icons"><svg height="16" viewbox="0 0 459 459" width="16" xmlns="http://www.w3.org/2000/svg"><path d="M0 382.5h459v-51H0v51zM0 255h459v-51H0v51zM0 76.5v51h459v-51H0z" fill="#FFF"></path></svg></i>
</div>
</div>
</header>
<nav class="mobile-sidebar">
<div class="nav-header">
<div class="logo-wrap">
<a class="nav-brand" href="/en"><img alt="PingCAP" src="/images/pingcap-logo.png"/></a>
</div>
</div>
<ul class="ul-base">
<li><a href="https://en.pingcap.com/">Cloud</a></li>
<li><a class="tidb-academy" href="/tidb-academy">TiDB Academy</a></li>
<li class="docs-type-selector " id="docsTypeSelector">
<p class="header-doc-nav">Docs</p>
<div class="header-dropdown-menu" id="docsTypeSelectorItem">
<a class="header-dropdown-item" href="/docs/stable/">TiDB</a>
<a class="header-dropdown-item" href="/docs/tidb-in-kubernetes/stable/">TiDB in Kubernetes</a>
<a class="header-dropdown-item" href="/docs/tidb-data-migration/stable/">TiDB Data Migration (DM)</a>
</div>
</li>
<li><a href="/success-stories">Success Stories</a></li>
<li class="sel"><a href="/blog">Blog</a></li>
<li><a class="link-download" href="/download">Free Download</a></li>
</ul>
<div class="nav-footer">
<div class="contact-list-wrap">
<div class="flex-list">
<h4 class="list-title"><strong>Contact</strong></h4>
<ul class="social ul-base">
<li><a class="twitter" href="https://twitter.com/PingCAP" target="_blank"><svg height="18" viewbox="0 0 612 612" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M612 116.258a250.714 250.714 0 0 1-72.088 19.772c25.929-15.527 45.777-40.155 55.184-69.411-24.322 14.379-51.169 24.82-79.775 30.48-22.907-24.437-55.49-39.658-91.63-39.658-69.334 0-125.551 56.217-125.551 125.513 0 9.828 1.109 19.427 3.251 28.606-104.326-5.24-196.835-55.223-258.75-131.174-10.823 18.51-16.98 40.078-16.98 63.101 0 43.559 22.181 81.993 55.835 104.479a125.556 125.556 0 0 1-56.867-15.756v1.568c0 60.806 43.291 111.554 100.693 123.104-10.517 2.83-21.607 4.398-33.08 4.398-8.107 0-15.947-.803-23.634-2.333 15.985 49.907 62.336 86.199 117.253 87.194-42.947 33.654-97.099 53.655-155.916 53.655-10.134 0-20.116-.612-29.944-1.721 55.567 35.681 121.536 56.485 192.438 56.485 230.948 0 357.188-191.291 357.188-357.188l-.421-16.253c24.666-17.593 46.005-39.697 62.794-64.861z"></path></svg></a></li>
<li><a class="linkedin" href="https://www.linkedin.com/company/pingcap/" target="_blank"><svg height="18" viewbox="0 0 438.536 438.535" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M5.424 145.895H99.64v282.932H5.424zM408.842 171.739c-19.791-21.604-45.967-32.408-78.512-32.408-11.991 0-22.891 1.475-32.695 4.427-9.801 2.95-18.079 7.089-24.838 12.419-6.755 5.33-12.135 10.278-16.129 14.844-3.798 4.337-7.512 9.389-11.136 15.104v-40.232h-93.935l.288 13.706c.193 9.139.288 37.307.288 84.508 0 47.205-.19 108.777-.572 184.722h93.931V270.942c0-9.705 1.041-17.412 3.139-23.127 4-9.712 10.037-17.843 18.131-24.407 8.093-6.572 18.13-9.855 30.125-9.855 16.364 0 28.407 5.662 36.117 16.987 7.707 11.324 11.561 26.98 11.561 46.966V428.82h93.931V266.664c-.007-41.688-9.897-73.328-29.694-94.925zM53.103 9.708c-15.796 0-28.595 4.619-38.4 13.848C4.899 32.787 0 44.441 0 58.529 0 72.42 4.758 84.034 14.275 93.358c9.514 9.325 22.078 13.99 37.685 13.99h.571c15.99 0 28.887-4.661 38.688-13.99 9.801-9.324 14.606-20.934 14.417-34.829-.19-14.087-5.047-25.742-14.561-34.973C81.562 14.323 68.9 9.708 53.103 9.708z"></path></svg></a></li>
<li><a class="reddit" href="https://www.reddit.com/r/TiDB/" target="_blank"><svg height="18" viewbox="0 0 279.748 279.748" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M279.748 133.142c0-19.299-15.701-35-35-35-10.768 0-20.674 4.812-27.279 13.064-18.532-8.431-39.663-13.626-62.015-15.271l19.206-60.692 42.895 9.294c3.285 12.782 14.901 22.258 28.693 22.258 16.336 0 29.627-13.29 29.627-29.626 0-16.336-13.291-29.627-29.627-29.627-11.801 0-21.999 6.941-26.759 16.95l-49.497-10.725a10.002 10.002 0 0 0-11.651 6.756L134.636 95.43c-26.164.638-50.988 6.053-72.356 15.775-6.606-8.251-16.512-13.063-27.28-13.063-19.299 0-35 15.701-35 35 0 9.373 3.683 18.173 10.222 24.709-3.9 8.37-5.875 17.076-5.875 25.936 0 24.048 14.396 46.492 40.538 63.199 25.447 16.264 59.183 25.221 94.989 25.221 35.808 0 69.542-8.957 94.989-25.221 26.142-16.707 40.538-39.151 40.538-63.199 0-8.859-1.975-17.565-5.875-25.936 6.539-6.537 10.222-15.336 10.222-24.709zM15.369 145.139c-2.212-3.59-3.369-7.688-3.369-11.997 0-12.682 10.317-23 23-23 5.444 0 10.558 1.851 14.649 5.258-14.622 8.302-26.132 18.289-34.28 29.739zm52.671 20.266c0-13.785 11.215-25 25-25s25 11.215 25 25-11.215 25-25 25-25-11.215-25-25zm123.119 57.054c-9.745 10.637-29.396 17.244-51.285 17.244-21.888 0-41.539-6.607-51.284-17.244a9.937 9.937 0 0 1-2.617-7.192 9.933 9.933 0 0 1 3.235-6.937 9.974 9.974 0 0 1 6.754-2.627c2.797 0 5.484 1.183 7.373 3.244 5.803 6.333 20.827 10.756 36.539 10.756s30.737-4.423 36.539-10.756a10.022 10.022 0 0 1 7.374-3.244c2.508 0 4.906.933 6.755 2.627a9.928 9.928 0 0 1 3.234 6.937 9.933 9.933 0 0 1-2.617 7.192zm-4.451-32.054c-13.785 0-25-11.215-25-25s11.215-25 25-25 25 11.215 25 25-11.215 25-25 25zm77.671-45.266c-8.147-11.45-19.657-21.436-34.28-29.739 4.092-3.408 9.205-5.258 14.649-5.258 12.683 0 23 10.318 23 23 0 4.309-1.157 8.407-3.369 11.997z"></path></svg></a></li>
<li><a class="google-plus" href="https://groups.google.com/forum/#!forum/tidb-user" target="_blank"><svg height="18" viewbox="0 0 491.858 491.858" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M377.472 224.957H201.319v58.718H308.79c-16.032 51.048-63.714 88.077-120.055 88.077-69.492 0-125.823-56.335-125.823-125.824 0-69.492 56.333-125.823 125.823-125.823 34.994 0 66.645 14.289 89.452 37.346l42.622-46.328c-34.04-33.355-80.65-53.929-132.074-53.929C84.5 57.193 0 141.693 0 245.928s84.5 188.737 188.736 188.737c91.307 0 171.248-64.844 188.737-150.989v-58.718l-.001-.001zM491.858 224.857h-36.031v-36.031h-30.886v36.031H388.91v30.883h36.031v36.032h30.886V255.74h36.031z"></path></svg></a></li>
<li><a class="stack-overflow" href="https://stackoverflow.com/questions/tagged/tidb" target="_blank"><svg height="18" viewbox="0 0 547.597 547.597" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M140.81 475.111h.024l189.91-.269c8.434-.013 15.3-6.886 15.3-15.318v-21.298c0-8.428-6.854-15.288-15.3-15.288l-189.91.264c-8.433.012-15.3 6.885-15.3 15.318v21.31c.001 8.427 6.855 15.281 15.276 15.281z"></path><path d="M58.667 517.854c.073 29.26.073 29.449 3.072 29.449h.055l10.612.294h.086s85.814 0 171.629-.036c42.914-.019 85.821-.05 118-.092 16.09-.019 29.505-.043 38.887-.074 17.803-.055 17.803-.055 17.803-3.072l.3-10.697V333.299c0-8.434-6.866-15.3-15.3-15.3h-11.909c-8.434 0-15.3 6.866-15.3 15.3V496.22c0 5.062-4.119 9.18-9.181 9.18H110.51c-5.061 0-9.18-4.118-9.18-9.18V333.299c0-8.434-6.867-15.3-15.3-15.3H73.82c-8.433 0-15.3 6.86-15.3 15.3 0 23.342.012 76.084.055 122.981.019 23.447.05 45.442.092 61.574z"></path><path d="M142.322 397.399l189.402 17.467c.478.043.948.062 1.413.062 7.956 0 14.468-5.985 15.159-13.917l1.83-21.096c.729-8.396-5.508-15.851-13.898-16.628l-189.102-17.461c-8.593-.795-15.869 5.441-16.653 13.825l-1.97 21.108a15.172 15.172 0 0 0 3.452 11.181 15.19 15.19 0 0 0 10.367 5.459zM437.636 208.849a15.253 15.253 0 0 0 17.694 12.443l21.065-3.678c8.311-1.451 13.898-9.395 12.454-17.706l-32.504-187.23c-1.42-8.207-9.21-13.917-17.692-12.448l-21.065 3.678c-8.311 1.451-13.898 9.395-12.454 17.705l32.502 187.236zM190.333 194.375l163.6 96.708a15.28 15.28 0 0 0 7.778 2.136c5.393 0 10.447-2.876 13.183-7.509l10.876-18.36c2.08-3.519 2.674-7.631 1.658-11.591a15.18 15.18 0 0 0-7.032-9.358l-163.6-96.714c-7.014-4.149-16.836-1.597-20.967 5.374l-10.869 18.36a15.2 15.2 0 0 0-1.658 11.591 15.21 15.21 0 0 0 7.031 9.363zM387.525 240.501a15.276 15.276 0 0 0 12.626 6.659c3.091 0 6.077-.924 8.635-2.681l17.405-11.934c6.953-4.768 8.752-14.314 4.015-21.292L323.29 54.104c-4.584-6.732-14.498-8.623-21.236-3.984l-17.737 12.21c-6.945 4.779-8.727 14.327-3.971 21.291l107.179 156.88zM154.482 302.319l183.465 49.156c1.298.349 2.632.526 3.966.526 6.903 0 12.98-4.67 14.762-11.347l5.508-20.624c2.179-8.152-2.681-16.555-10.826-18.74l-183.465-49.162c-8.017-2.148-16.604 2.852-18.728 10.826l-5.508 20.63c-2.179 8.142 2.68 16.551 10.826 18.735z"></path></svg></a></li>
</ul>
</div>
<div class="subscribe">
<a href="https://share.hsforms.com/1e2W03wLJQQKPd1d9rCbj_Q2npzm"><button class="btn btn-subscribe f-tc" style="margin-left: 0.75rem;">Subscribe to Blog</button></a>
</div>
</div>
<div class="container">
<a class="btn-lang" href="/blog-cn" id="lang">中文</a>
</div>
</div>
</nav>
<div class="blog">
<div class="blogArticle__container">
<div class="archive"><div class="article-nav">
<a href="/blog/#Engineering">BLOG HOME</a> <span> &gt; </span>Engineering</div><div class="content markdown-body">
<h1 class="title">Doubling System Read Throughput with Only 26 Lines of Code</h1>
<ul class="blog-post-meta">
<li class="meta-item">
<img alt="Date icon" src="/images/svgs/icon-date.svg"/>Wed, Feb 5, 2020</li>
<li class="meta-item">
<img alt="Pen icon" src="/images/svgs/icon-writer.svg"/>Edward Huang</li>
</ul>
<div class="blog-text"><p><img alt="Doubling System Read Throughput with Only 26 Lines of Code" class="lazy" data-original="https://download.pingcap.com/images/blog/follower-read-load-balancing-consistent-read.png" src="/images/svgs/loader-spinner.svg"/></p>
<p>On Dec 20, 2019, we released <a href="https://pingcap.com/docs/v3.1/releases/3.1.0-beta/">TiDB 3.1 Beta</a>. In this version, <a href="https://en.wikipedia.org/wiki/TiDB">TiDB</a> introduced two significant features, <a href="https://pingcap.com/docs/v3.1/reference/performance/follower-read/">Follower Read</a> and <a href="https://pingcap.com/docs/v3.1/how-to/maintain/backup-and-restore/br/">Backup &amp; Restore (BR)</a>, and enriched <a href="https://pingcap.com/docs/v3.1/reference/performance/optimizer-hints/">optimizer hints</a>.</p>
<p>For TiDB 3.1 Beta, Follower Read is a highlight open-source feature. To understand how important this feature is, you'll need a bit of background. TiDB's storage engine, <a href="https://pingcap.com/docs/v3.1/architecture/#tikv-server">TiKV</a>, stores data in basic units called <a href="https://pingcap.com/docs/v3.1/glossary/#regionpeerraft-group">Regions</a>. Multiple replicas of a Region form a <a href="https://pingcap.com/docs/v3.1/glossary/#regionpeerraft-group">Raft group</a>. When a read hotspot appears in a Region, the Region <a href="https://pingcap.com/docs/v3.1/glossary/#leaderfollowerlearner">leader</a> can become a read bottleneck for the entire system. In this situation, enabling the Follower Read feature can significantly reduce the load on the leader and improve the read throughput of the whole system by balancing the load among multiple <a href="https://pingcap.com/docs/v3.1/glossary/#leaderfollowerlearner">followers</a>.</p>
<p>We wrote only <a href="https://github.com/tikv/tikv/pull/5051">26 lines of code</a> to implement Follower Read. In our benchmark test, when this feature was enabled, we could roughly double the read throughput of the entire system.</p>
<p>In this post, I'll guide you through why we introduced Follower Read, how we implement it, and our future plans for it.</p>
<p>Note that this post assumes that you have some basic knowledge of the <a href="https://raft.github.io/">Raft consensus algorithm</a> and <a href="https://docs.pingcap.com/tidb/v4.0/architecture">TiDB's architecture</a>.</p>
<h2 id="what-is-follower-read">What is Follower Read</h2>
<p><a href="https://pingcap.com/docs/v3.1/reference/performance/follower-read/#overview">The Follower Read feature</a> lets any follower replica in a Region serve a read request under the premise of <a href="https://pingcap.com/docs/v3.1/reference/performance/follower-read/#strongly-consistent-reads">strongly consistent reads</a>.</p>
<p>This feature improves the throughput of the TiDB cluster and reduces the load on the Raft leader. It contains a series of load balancing mechanisms that offload TiKV read loads from the leader replica to the follower replicas in a Region.</p>
<p>TiKV's Follower Read implementation guarantees the linearizability of single-row data reading. Combined with <a href="https://en.wikipedia.org/wiki/Snapshot_isolation">snapshot isolation</a> in TiDB, this implementation also provides users with strongly consistent reads.</p>
<h2 id="why-we-introduced-follower-read">Why we introduced Follower Read</h2>
<p>In the TiKV architecture, we use the Raft algorithm to ensure data consistency. But in the previous mechanism, only the leader in a Region handled heavy workloads, and the calculation resources of followers were not put to use. Therefore, we introduced Follower Read to handle read requests on followers to reduce the load on the leader.</p>
<h3 id="the-tikv-architecture">The TiKV architecture</h3>
<p>TiKV uses the Raft algorithm to guarantee data consistency. The goal of TiKV is to support 100+ TB of data, but it is impossible for one Raft group to do that. Therefore, we need to use multiple Raft groups, which is Multi-Raft. See our previous post <a href="https://pingcap.com/blog/2017-08-15-multi-raft/">The Design and Implementation of Multi-Raft</a>.</p>
<p><img alt="Implementing Raft in the TiKV architecture" class="lazy" data-original="https://download.pingcap.com/images/blog/implementing-raft-in-the-tikv-architecture.png" src="/images/svgs/loader-spinner.svg"/></p>
<div class="caption-center"> Implementing Raft in the TiKV architecture </div>
<p>TiKV divides data into Regions. By default, each Region has three replicas and these Region replicas form a Raft group. As data writes increase, if the size of the Region or the number of keys reaches a threshold, a <a href="https://pingcap.com/docs/v3.1/glossary/#region-split">Region Split</a> occurs. Conversely, if data is deleted and the size of a Region or the amount of keys shrinks, we can use Region Merge to merge smaller adjacent Regions. This relieves some stress on Raftstore.</p>
<h3 id="the-problem-with-the-tikv-architecture">The problem with the TiKV architecture</h3>
<p>The Raft algorithm achieves consensus via an elected leader. A server in a Raft group is either a leader or a follower, and, if a leader is unavailable, it can be a candidate in an election. The leader replicates logs to the followers.</p>
<p>Although TiKV can spread Regions evenly on each node, only the leader can provide external services. The other two followers only receive the data replicated from the leader, or vote to elect a Raft leader when doing a failover. Simply put, at the Region level, <strong>only the leader deals with heavy workloads, while followers are maintained as cold standbys</strong>.</p>
<p>Sometimes when there is some hot data, the resources of the Region leader's machine are fully occupied. Although we can forcibly split the Region and then move the data to another machine, this operation always lags, and the calculation resources of followers are not used.</p>
<p>Here comes a question: can we handle the client's read request on followers? If yes, we can relieve the load on the leader.</p>
<p>The solution is Follower Read.</p>
<h2 id="how-we-implement-follower-read">How we implement Follower Read</h2>
<p>The implementation of Follower Read is based on the <code>ReadIndex</code> algorithm. Before elaborating on Follower Read, let me introduce <code>ReadIndex</code> first.</p>
<h3 id="the-readindex-algorithm">The <code>ReadIndex</code> algorithm</h3>
<p>This section discusses how the <code>ReadIndex</code> algorithm solves the linearizability issue.</p>
<h4 id="the-linearizability-issue-for-the-raft-algorithm">The linearizability issue for the Raft algorithm</h4>
<p>How do we ensure that we can read the latest data on followers? Can we just return the data about the latest committed index on followers to the client?</p>
<p>The answer is no, because Raft is a quorum-based algorithm. To commit a log, you don't need to successfully write data to all the replicas of a Region (also known as <a href="https://pingcap.com/docs/v3.1/glossary/#regionpeerraft-group">peers</a>).  Instead, when a log is committed to the <em>majority</em> of peers, it means that it is successfully written to TiKV. In this case, the local data on a follower might be stale. This violates linearizability.</p>
<p>In fact, in trivial Raft implementation, even if the leader handles all loads, the stale data problem may still occur. For example, when a network partition occurs, the old leader is isolated in the minority of nodes. At the same time, the majority of nodes have elected a new leader. But the old leader doesn't know that, and it may return stale data to the client during its leader lease.</p>
<h4 id="readindex-as-the-solution-to-the-linearizability-issue"><code>ReadIndex</code> as the solution to the linearizability issue</h4>
<p>The quorum reads mechanism helps solve this problem, but it might consume a lot of resources or take too long. Can we improve its effectiveness? The crucial issue is that the old leader is not sure whether it is the latest leader. Therefore, we need a method for the leader to confirm its leader state. This method is called the <em><code>ReadIndex</code> algorithm</em>. It works as follows:</p>
<ol>
<li>
<p>When the current leader processes a read request, the system records the current leader's latest committed index.</p>
</li>
<li>
<p>The current leader ensures that it's still the leader by sending a heartbeat to the quorum.</p>
</li>
<li>
<p>After the leader confirms its leader state, it returns this entry.</p>
</li>
</ol>
<p>This way, linearizability is not violated. Although the <code>ReadIndex</code> algorithm needs network communication for the majority of the cluster, this communication just transmits metadata. It can remarkably reduce network I/O, and thus increase the throughput. Furthermore, TiKV goes beyond the standard <code>ReadIndex</code> algorithm and implements <code>LeaseRead</code>, which guarantees that the leader lease is shorter than the election timeout of re-electing a new leader.</p>
<h3 id="implementation-and-issues-of-follower-read">Implementation and issues of Follower Read</h3>
<p>This section shows how we implement Follower Read and some of this feature's issues.</p>
<h4 id="the-current-implementation-of-follower-read">The current implementation of Follower Read</h4>
<p>How do we ensure that we can read the latest data on followers? Maybe you'll consider this common policy: the request is forwarded to the leader, and then the leader returns the latest committed data. The follower is used as a proxy. The idea is simple and safe to implement.</p>
<p>You can also optimize this policy. The leader only needs to tell followers the latest committed index, because in any case, even if a follower hasn't stored this log locally, the log is applied locally sooner or later.</p>
<p>Based on this thought, TiDB currently implements the Follower Read feature this way:</p>
<ol>
<li>
<p>When the client sends a read request to a follower, the follower requests the leader's committed index.</p>
</li>
<li>
<p>After the follower gets the leader's latest committed index and applies the index to itself, the follower returns this entry to the client.</p>
</li>
</ol>
<h4 id="issues-for-follower-read">Issues for Follower Read</h4>
<p>Currently, the Follower Read feature has two issues:</p>
<p><strong>Issue #1: linearizability</strong></p>
<p>TiKV uses an asynchronous Apply, which might violate linearizability. Although the leader tells followers the latest committed index, the leader applies this log asynchronously. A follower may apply this s log before the leader does. As a result, we can read this entry on the follower, but it may take a while to read it on the leader.</p>
<p>Although we can't ensure linearizability for the Raft layer, Follower Read can guarantee snapshot isolation for the database distributed transaction layer. If you're familiar with the <a href="http://www.matrixscience.com/help/percolator_help.html">Percolator algorithm</a>, you can get that:</p>
<ul>
<li>When we execute a point get query, we use <code>UINT64_MAX</code> as the timestamp to read data. Because only one row of data in only one Region is accessed, we can guarantee snapshot isolation for a transaction.</li>
<li>If the data for the committed timestamp (ts) can be read on the follower, but other SQL statements within the same transaction temporarily can't read this ts on the leader, a lock inevitably occurs. The subsequent processing of the lock can guarantee snapshot isolation.</li>
</ul>
<p>The two facts above ensure that when Follower Read is enabled, TiDB's transaction still implements snapshot isolation. Thus, transaction correctness isn't affected.</p>
<p><strong>Issue #2: read latency</strong></p>
<p>Our current Follower Read implementation still uses a <a href="https://en.wikipedia.org/wiki/Remote_procedure_call">remote procedure call</a> (RPC) to ask the leader for the committed index. Therefore, even though we use Follower Read, read latency remains high.</p>
<p>For this issue, even though this solution doesn't significantly improve latency, it helps improve read throughput and reduce the load on the leader.</p>
<p>Therefore, the Follower Read feature is a fine optimization.</p>
<h2 id="benchmarks-for-follower-read">Benchmarks for Follower Read</h2>
<p>We ran tests in four scenarios and arrived at the following conclusions:</p>
<ul>
<li>In the multi-region architecture, when Follower Read was enabled, the client could read data from the local data center. This reduced the network bandwidth usage. When the data volume reached a certain scale, Follower Read remarkably improved the system performance. (See Scenario #1 and Scenario #2 below.)</li>
<li>Follower Read can effectively increase the read throughput of the entire system and balance the hotspot read pressure. (See Scenario #3 and Scenario #4 below.)</li>
</ul>
<p>You can read this section to get more details.</p>
<h3 id="test-environment">Test environment</h3>
<p>We used the following machines for testing:</p>
<ul>
<li>UCloud 16C 32 GB 100 GB SSD in Beijing, China</li>
<li>UCloud 16C 32 GB 100 GB SSD in Shanghai, China</li>
</ul>
<p>We tested the bandwidth and latency, and determined the following:</p>
<ul>
<li>Bandwidth was 297 Mbits/sec.</li>
<li>Latency ranged from 27.7 to 28.3 ms.</li>
</ul>
<p>We used Yahoo! Cloud Serving Benchmark (YCSB) to import 10,000,000 rows of data and tested the scan performance for different rows.</p>
<p>We performed raw key-value (KV) scan tests. By adjusting the number of scan keys, we got requests of different data sizes for testing.</p>
<h3 id="test-results">Test results</h3>
<h4 id="scenario-1">Scenario #1</h4>
<p>Scenario description: The follower and the client were in the same data center (DC). The leader was in a data center in another region. The leader served read requests.</p>
<p>Test results:</p>
<table>
<tr>
<td><strong>Number of scan keys</strong>
</td>
<td><strong>QPS</strong>
</td>
<td><strong>P99 latency for TiKV</strong>
</td>
<td><strong>P99 latency for the client</strong>
</td>
</tr>
<tr>
<td>10
   </td>
<td>3,110
   </td>
<td>43 ms
   </td>
<td>115 ms
   </td>
</tr>
<tr>
<td>100
   </td>
<td>314
   </td>
<td>450 ms
   </td>
<td>7,888 ms
   </td>
</tr>
<tr>
<td>200
   </td>
<td>158
   </td>
<td>480 ms
   </td>
<td>13,180 ms
   </td>
</tr>
<tr>
<td>500
   </td>
<td>63
   </td>
<td>500 ms
   </td>
<td>23,630 ms
   </td>
</tr>
<tr>
<td>1,000
   </td>
<td>31
   </td>
<td>504 ms
   </td>
<td>34,693 ms
   </td>
</tr>
<tr>
<td>1,500
   </td>
<td>8
   </td>
<td>507 ms
   </td>
<td>50,220 ms
   </td>
</tr>
</table>
<p>Result analysis:</p>
<p>When the latency between the client and TiKV increased, due to the sliding window mechanism, the corresponding TCP connection bandwidth decreased. When the data volume was large, we even observed a lot of <code>DeadlineExceeded</code> logs.</p>
<p>The reason behind the high P99 latency for TiKV is because the leader lease expired. One-third of the read requests should read <code>ReadIndex</code> before they are executed.</p>
<h4 id="scenario-2">Scenario #2</h4>
<p>Scenario description: The follower and the client were in the same data center. The leader was in a data center in another region. The follower served read requests.</p>
<p>Test results:</p>
<table>
<tr>
<td><strong>Number of scan keys</strong>
</td>
<td><strong>QPS</strong>
</td>
<td><strong>P99 latency for TiKV</strong>
</td>
<td><strong>P99 latency for the client</strong>
</td>
</tr>
<tr>
<td>10
   </td>
<td>3,836
   </td>
<td>88 ms
   </td>
<td>126 ms
   </td>
</tr>
<tr>
<td>100
   </td>
<td>3,087
   </td>
<td>127 ms
   </td>
<td>140 ms
   </td>
</tr>
<tr>
<td>200
   </td>
<td>1,966
   </td>
<td>130 ms
   </td>
<td>323 ms
   </td>
</tr>
<tr>
<td>500
   </td>
<td>920
   </td>
<td>256 ms
   </td>
<td>1,026 ms
   </td>
</tr>
<tr>
<td>1,000
   </td>
<td>446
   </td>
<td>504 ms
   </td>
<td>2,651 ms
   </td>
</tr>
<tr>
<td>1,500
   </td>
<td>285
   </td>
<td>980 ms
   </td>
<td>4,525 ms
   </td>
</tr>
</table>
<p>Result analysis:</p>
<p>Follower Read reduced cross-DC traffic. Thus, it avoided the impact of the TCP sliding window mechanism on a high-latency network. When the amount of data in a request was small, the impact on the cross-DC latency was big. When the amount of data in a request was big, the impact on the cross-DC latency was small. In this case, when Follower Read was enabled, read throughput did not change very much.</p>
<h4 id="scenario-3">Scenario #3</h4>
<p>Scenario description: The leader and the client were on the same node. The leader served read requests.</p>
<p>Test results:</p>
<table>
<tr>
<td><strong>Number of scan keys</strong>
</td>
<td><strong>QPS</strong>
</td>
<td><strong>P99 latency for TiKV</strong>
</td>
<td><strong>P99 latency for the client</strong>
</td>
</tr>
<tr>
<td>10
   </td>
<td>18,865
   </td>
<td>31 ms
   </td>
<td>33 ms
   </td>
</tr>
<tr>
<td>100
   </td>
<td>4,233
   </td>
<td>58 ms
   </td>
<td>267 ms
   </td>
</tr>
<tr>
<td>200
   </td>
<td>2,321
   </td>
<td>94 ms
   </td>
<td>550 ms
   </td>
</tr>
<tr>
<td>500
   </td>
<td>1,008
   </td>
<td>130 ms
   </td>
<td>1,455 ms
   </td>
</tr>
<tr>
<td>1,000
   </td>
<td>480
   </td>
<td>330 ms
   </td>
<td>3,228 ms
   </td>
</tr>
<tr>
<td>1,500
   </td>
<td>298
   </td>
<td>450 ms
   </td>
<td>6,438 ms
   </td>
</tr>
</table>
<p>Result analysis:</p>
<p>The client had higher latency than TiKV. We ran netstat and found that there were many packets in the TCP Send-Q. This means that the TCP sliding window mechanism limited the bandwidth.</p>
<h4 id="scenario-4">Scenario #4</h4>
<p>Scenario description: The leader, client, and follower were in the same data center. The follower served read requests.</p>
<p>Test results:</p>
<table>
<tr>
<td><strong>Number of scan keys</strong>
</td>
<td><strong>QPS</strong>
</td>
<td><strong>P99 latency for TiKV</strong>
</td>
<td><strong>P99 latency for the client</strong>
</td>
</tr>
<tr>
<td>10
   </td>
<td>15,021
   </td>
<td>31 ms
   </td>
<td>34 ms
   </td>
</tr>
<tr>
<td>100
   </td>
<td>3,859
   </td>
<td>62 ms
   </td>
<td>272 ms
   </td>
</tr>
<tr>
<td>200
   </td>
<td>2,186
   </td>
<td>120 ms
   </td>
<td>560 ms
   </td>
</tr>
<tr>
<td>500
   </td>
<td>947
   </td>
<td>243 ms
   </td>
<td>1,305 ms
   </td>
</tr>
<tr>
<td>1,000
   </td>
<td>450
   </td>
<td>480 ms
   </td>
<td>3,189 ms
   </td>
</tr>
<tr>
<td>1,500
   </td>
<td>277
   </td>
<td>763 ms
   </td>
<td>5,058 ms
   </td>
</tr>
</table>
<p>Result analysis:</p>
<p>When the amount of data in the read request was small and the request processing time was short, the impact of Follower Read on the latency was big. This was because the Follower Read feature included an internal remote procedure call (RPC). The RPC operation took up a large portion of the read request processing time. Therefore, it had a big influence on read throughput.</p>
<h2 id="whats-next-for-follower-read">What's next for Follower Read</h2>
<p>This feature seems simple, but it's really important. In the future, we'll use it in even more ways to improve TiDB's performance.</p>
<h3 id="strategies-for-varied-heat-data">Strategies for varied-heat data</h3>
<p>You might ask me a question: if I run a large query on a table, will it affect the ongoing <a href="https://en.wikipedia.org/wiki/Online_transaction_processing">online transaction processing</a> (OLTP) transaction？Although we have an I/O priority queue built in TiKV, which prioritizes important OLTP requests, it still consumes the resources of the machine with the leader state.</p>
<p>A corner case is a small hot table with many more read operations than write operations. Although hot data is cached in memory, when the data is extremely hot, a CPU or network I/O bottleneck occurs.</p>
<p>Our previous post <a href="https://pingcap.com/blog/2017-07-20-tidbinternal3/">TiDB Internal (III) - Scheduling</a> mentions that we use a separate component called <a href="https://pingcap.com/docs/v3.1/architecture/#placement-driver-server">Placement Driver</a> (PD) to schedule and load-balance Regions in the TiKV cluster. Currently, the scheduling work is limited to splitting, merging, and moving Regions, and transferring the leader. But in the near future, TiDB will be able to dynamically use different replica strategies for data of different heat degrees.</p>
<p>For example, if we find a small table extremely hot, PD can quickly let TiKV dynamically create multiple (more than three) read-only replicas of this data, and use the Follower Read feature to divert the load from the leader. When the load pressure is mitigated, the read-only replicas are destroyed. Because each Region in TiKV is small (96 MB by default), TiDB can be very flexible and lightweight when doing this.</p>
<h3 id="local-read-based-on-follower-read">Local Read based on Follower Read</h3>
<p>Currently, even though TiDB is deployed across data centers and distributes data replicas among these data centers, it is the leader that provides services for each piece of data. This means that applications need to be as close to the leader as possible. Therefore, we usually recommend that users deploy applications in a single data center, and then make PD focus leaders on this data center to process read and write requests faster. Raft is only used to achieve high availability across data centers.</p>
<p>For some read requests, if we can process these requests on a nearby node, we can reduce the read latency and improve read throughput.</p>
<p>As mentioned above, the current implementation of Follower Read does little to reduce read latency. Can we get the local committed log without asking the leader? Yes, in some cases.</p>
<p>As we discussed in our previous post <a href="https://pingcap.com/blog/2016-11-17-mvcc-in-tikv/">MVCC in TiKV</a>, TiDB uses <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">multi-version concurrency control</a> (MVCC) to control transaction concurrency. Each entry has a unique, monotonically increasing version number.</p>
<p>Next, we'll combine Follower Read with MVCC. If the version number of the data in the latest committed log on the local node is greater than that of the transaction initiated by the client, the system returns the data in the latest committed log on the local node. This won't violate the <a href="https://en.wikipedia.org/wiki/ACID">atomicity, consistency, isolation, durability</a> (ACID) properties of transactions.</p>
<p>In addition, for some scenarios where data consistency is not a strict requirement, it makes sense to directly support reads of low isolation level in the future. When TiDB supports reads of low isolation level, its performance might improve dramatically.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The Follower Read feature uses a series of load balancing mechanisms to offload read requests on the Raft leader onto its followers in a Region. It ensures the linearizability of single-row data reads and offers strongly consistent reads when combined with TiDB's snapshot isolation.</p>
<p>Follower Read helps reduce the load on the Region leader and substantially enhances the throughput of the entire system. If you'd like to try it out, see our <a href="https://pingcap.com/docs/v3.1/reference/performance/follower-read/">user document</a>.</p>
<p>We've just taken the first step to craft Follower Read, and we'll make continuous efforts to optimize this feature in the future. If you're interested in it, you're welcome to test it or contribute to <a href="https://github.com/tikv">our project</a>.</p>
</div>
</div>
<div class="article-toc"></div><div class="ssba-wrap">
<div class="ssba">
<a class="ssba_twitter_share" data-site="" href="http://twitter.com/share?url=https%3a%2f%2fpingcap.com%2fblog%2fdoubling-system-read-throughput-with-only-26-lines-of-code%2f" target="_blank">
<img alt="Twitter icon" src="/images/svgs/twitter-icon.svg"/>
</a>
<a class="ssba_reddit_share" data-site="reddit" href="http://reddit.com/submit?url=https%3a%2f%2fpingcap.com%2fblog%2fdoubling-system-read-throughput-with-only-26-lines-of-code%2f&amp;title=Doubling%20System%20Read%20Throughput%20with%20Only%2026%20Lines%20of%20Code" target="_blank">
<img alt="Reddit icon" src="/images/svgs/reddit-icon.svg"/>
</a>
<a class="ssba_facebook_share" data-site="" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fpingcap.com%2fblog%2fdoubling-system-read-throughput-with-only-26-lines-of-code%2f" target="_blank">
<img alt="Fackbook icon" src="/images/svgs/facebook-icon.svg"/>
</a>
<a class="ssba_linkedin_share" data-site="linkedin" href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpingcap.com%2fblog%2fdoubling-system-read-throughput-with-only-26-lines-of-code%2f" target="_blank">
<img alt="Linkedin icon" src="/images/svgs/linkedin-icon.svg"/>
</a>
<a class="ssba_hackernews_share" data-site="hackernews" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fpingcap.com%2fblog%2fdoubling-system-read-throughput-with-only-26-lines-of-code%2f&amp;t=Doubling%20System%20Read%20Throughput%20with%20Only%2026%20Lines%20of%20Code" target="_blank">
<img alt="Hacker News icon" src="/images/svgs/hacker-news-icon.svg"/>
</a>
</div>
</div>
<div class="trackable-btns">
<a href="/download" onclick="trackViews('Doubling System Read Throughput with Only 26 Lines of Code', 'download-tidb-btn-bottom')"><button>Download
                        TiDB</button></a>
<a href="https://share.hsforms.com/1e2W03wLJQQKPd1d9rCbj_Q2npzm" onclick="trackViews('Doubling System Read Throughput with Only 26 Lines of Code', 'subscribe-blog-btn-bottom')"><button>Subscribe to
                        Blog</button></a>
</div>
</div>
<div class="sidebar-page">
<div class="sticky-sidebar">
<p class="toc-title">What’s on this page</p>
<div id="smart_toc_wrapper"></div>
</div>
</div>
</div>
</div>
<footer>
<div class="container">
<div class="flex-list-wrap">
<div class="flex-list">
<h4 class="list-title"><strong>Product</strong></h4>
<ul>
<li><a href="/docs/v3.0/">TiDB</a></li>
<li><a href="/docs/v3.0/reference/tispark/">TiSpark</a></li>
<li><a href="/docs/v3.0/roadmap/">Roadmap</a></li>
</ul>
</div>
<div class="flex-list">
<h4 class="list-title"><strong>Docs</strong></h4>
<ul>
<li><a href="/docs/stable/quick-start-with-tidb/">Quick Start</a></li>
<li><a href="/blog/2017-07-24-tidbbestpractice/">Best Practices</a></li>
<li><a href="/docs/stable/faq/tidb/">FAQ</a></li>
<li><a href="/docs/stable/reference/tools/user-guide/">TiDB Tools</a></li>
<li><a href="/docs/dev/releases/rn/">Release Notes</a></li>
</ul>
</div>
<div class="flex-list">
<h4 class="list-title"><strong>Resources</strong></h4>
<ul>
<li><a href="/blog/">Blog</a></li>
<li><a href="/weekly/">Monthly</a></li>
<li><a href="https://github.com/pingcap" target="_blank">GitHub</a></li>
<li><a href="/community">TiDB Community</a></li>
</ul>
</div>
<div class="flex-list">
<h4 class="list-title"><strong>Company</strong></h4>
<ul>
<li><a href="/about/">About</a></li>
<li><a href="https://angel.co/pingcap-1/jobs" target="_blank">Careers</a></li>
<li><a href="/news/">News</a></li>
<li><a href="/contact-us/">Contact Us</a></li>
<li><a href="/privacy-policy/">Privacy Policy</a></li>
<li><a href="/terms-of-service/">Terms of Service</a></li>
</ul>
</div>
</div>
<div class="contact-list-wrap">
<div class="flex-list">
<h4 class="list-title"><strong>Connect</strong></h4>
<ul>
<li><a class="twitter" href="https://twitter.com/PingCAP" target="_blank"><svg height="19" viewbox="0 0 612 612" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M612 116.258a250.714 250.714 0 0 1-72.088 19.772c25.929-15.527 45.777-40.155 55.184-69.411-24.322 14.379-51.169 24.82-79.775 30.48-22.907-24.437-55.49-39.658-91.63-39.658-69.334 0-125.551 56.217-125.551 125.513 0 9.828 1.109 19.427 3.251 28.606-104.326-5.24-196.835-55.223-258.75-131.174-10.823 18.51-16.98 40.078-16.98 63.101 0 43.559 22.181 81.993 55.835 104.479a125.556 125.556 0 0 1-56.867-15.756v1.568c0 60.806 43.291 111.554 100.693 123.104-10.517 2.83-21.607 4.398-33.08 4.398-8.107 0-15.947-.803-23.634-2.333 15.985 49.907 62.336 86.199 117.253 87.194-42.947 33.654-97.099 53.655-155.916 53.655-10.134 0-20.116-.612-29.944-1.721 55.567 35.681 121.536 56.485 192.438 56.485 230.948 0 357.188-191.291 357.188-357.188l-.421-16.253c24.666-17.593 46.005-39.697 62.794-64.861z"></path></svg> Twitter</a></li>
<li><a class="linkedin" href="https://www.linkedin.com/company/pingcap/" target="_blank"><svg height="16" viewbox="0 0 438.536 438.535" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M5.424 145.895H99.64v282.932H5.424zM408.842 171.739c-19.791-21.604-45.967-32.408-78.512-32.408-11.991 0-22.891 1.475-32.695 4.427-9.801 2.95-18.079 7.089-24.838 12.419-6.755 5.33-12.135 10.278-16.129 14.844-3.798 4.337-7.512 9.389-11.136 15.104v-40.232h-93.935l.288 13.706c.193 9.139.288 37.307.288 84.508 0 47.205-.19 108.777-.572 184.722h93.931V270.942c0-9.705 1.041-17.412 3.139-23.127 4-9.712 10.037-17.843 18.131-24.407 8.093-6.572 18.13-9.855 30.125-9.855 16.364 0 28.407 5.662 36.117 16.987 7.707 11.324 11.561 26.98 11.561 46.966V428.82h93.931V266.664c-.007-41.688-9.897-73.328-29.694-94.925zM53.103 9.708c-15.796 0-28.595 4.619-38.4 13.848C4.899 32.787 0 44.441 0 58.529 0 72.42 4.758 84.034 14.275 93.358c9.514 9.325 22.078 13.99 37.685 13.99h.571c15.99 0 28.887-4.661 38.688-13.99 9.801-9.324 14.606-20.934 14.417-34.829-.19-14.087-5.047-25.742-14.561-34.973C81.562 14.323 68.9 9.708 53.103 9.708z"></path></svg> LinkedIn</a></li>
<li><a class="reddit" href="https://www.reddit.com/r/TiDB/" target="_blank"><svg height="18" viewbox="0 0 279.748 279.748" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M279.748 133.142c0-19.299-15.701-35-35-35-10.768 0-20.674 4.812-27.279 13.064-18.532-8.431-39.663-13.626-62.015-15.271l19.206-60.692 42.895 9.294c3.285 12.782 14.901 22.258 28.693 22.258 16.336 0 29.627-13.29 29.627-29.626 0-16.336-13.291-29.627-29.627-29.627-11.801 0-21.999 6.941-26.759 16.95l-49.497-10.725a10.002 10.002 0 0 0-11.651 6.756L134.636 95.43c-26.164.638-50.988 6.053-72.356 15.775-6.606-8.251-16.512-13.063-27.28-13.063-19.299 0-35 15.701-35 35 0 9.373 3.683 18.173 10.222 24.709-3.9 8.37-5.875 17.076-5.875 25.936 0 24.048 14.396 46.492 40.538 63.199 25.447 16.264 59.183 25.221 94.989 25.221 35.808 0 69.542-8.957 94.989-25.221 26.142-16.707 40.538-39.151 40.538-63.199 0-8.859-1.975-17.565-5.875-25.936 6.539-6.537 10.222-15.336 10.222-24.709zM15.369 145.139c-2.212-3.59-3.369-7.688-3.369-11.997 0-12.682 10.317-23 23-23 5.444 0 10.558 1.851 14.649 5.258-14.622 8.302-26.132 18.289-34.28 29.739zm52.671 20.266c0-13.785 11.215-25 25-25s25 11.215 25 25-11.215 25-25 25-25-11.215-25-25zm123.119 57.054c-9.745 10.637-29.396 17.244-51.285 17.244-21.888 0-41.539-6.607-51.284-17.244a9.937 9.937 0 0 1-2.617-7.192 9.933 9.933 0 0 1 3.235-6.937 9.974 9.974 0 0 1 6.754-2.627c2.797 0 5.484 1.183 7.373 3.244 5.803 6.333 20.827 10.756 36.539 10.756s30.737-4.423 36.539-10.756a10.022 10.022 0 0 1 7.374-3.244c2.508 0 4.906.933 6.755 2.627a9.928 9.928 0 0 1 3.234 6.937 9.933 9.933 0 0 1-2.617 7.192zm-4.451-32.054c-13.785 0-25-11.215-25-25s11.215-25 25-25 25 11.215 25 25-11.215 25-25 25zm77.671-45.266c-8.147-11.45-19.657-21.436-34.28-29.739 4.092-3.408 9.205-5.258 14.649-5.258 12.683 0 23 10.318 23 23 0 4.309-1.157 8.407-3.369 11.997z"></path></svg>Reddit</a></li>
<li><a class="google-plus" href="https://groups.google.com/forum/#!forum/tidb-user" target="_blank"><svg height="20" viewbox="0 0 491.858 491.858" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M377.472 224.957H201.319v58.718H308.79c-16.032 51.048-63.714 88.077-120.055 88.077-69.492 0-125.823-56.335-125.823-125.824 0-69.492 56.333-125.823 125.823-125.823 34.994 0 66.645 14.289 89.452 37.346l42.622-46.328c-34.04-33.355-80.65-53.929-132.074-53.929C84.5 57.193 0 141.693 0 245.928s84.5 188.737 188.736 188.737c91.307 0 171.248-64.844 188.737-150.989v-58.718l-.001-.001zM491.858 224.857h-36.031v-36.031h-30.886v36.031H388.91v30.883h36.031v36.032h30.886V255.74h36.031z"></path></svg>Google Group</a></li>
<li><a class="stack-overflow" href="https://stackoverflow.com/questions/tagged/tidb" target="_blank"><svg height="17" viewbox="0 0 547.597 547.597" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M140.81 475.111h.024l189.91-.269c8.434-.013 15.3-6.886 15.3-15.318v-21.298c0-8.428-6.854-15.288-15.3-15.288l-189.91.264c-8.433.012-15.3 6.885-15.3 15.318v21.31c.001 8.427 6.855 15.281 15.276 15.281z"></path><path d="M58.667 517.854c.073 29.26.073 29.449 3.072 29.449h.055l10.612.294h.086s85.814 0 171.629-.036c42.914-.019 85.821-.05 118-.092 16.09-.019 29.505-.043 38.887-.074 17.803-.055 17.803-.055 17.803-3.072l.3-10.697V333.299c0-8.434-6.866-15.3-15.3-15.3h-11.909c-8.434 0-15.3 6.866-15.3 15.3V496.22c0 5.062-4.119 9.18-9.181 9.18H110.51c-5.061 0-9.18-4.118-9.18-9.18V333.299c0-8.434-6.867-15.3-15.3-15.3H73.82c-8.433 0-15.3 6.86-15.3 15.3 0 23.342.012 76.084.055 122.981.019 23.447.05 45.442.092 61.574z"></path><path d="M142.322 397.399l189.402 17.467c.478.043.948.062 1.413.062 7.956 0 14.468-5.985 15.159-13.917l1.83-21.096c.729-8.396-5.508-15.851-13.898-16.628l-189.102-17.461c-8.593-.795-15.869 5.441-16.653 13.825l-1.97 21.108a15.172 15.172 0 0 0 3.452 11.181 15.19 15.19 0 0 0 10.367 5.459zM437.636 208.849a15.253 15.253 0 0 0 17.694 12.443l21.065-3.678c8.311-1.451 13.898-9.395 12.454-17.706l-32.504-187.23c-1.42-8.207-9.21-13.917-17.692-12.448l-21.065 3.678c-8.311 1.451-13.898 9.395-12.454 17.705l32.502 187.236zM190.333 194.375l163.6 96.708a15.28 15.28 0 0 0 7.778 2.136c5.393 0 10.447-2.876 13.183-7.509l10.876-18.36c2.08-3.519 2.674-7.631 1.658-11.591a15.18 15.18 0 0 0-7.032-9.358l-163.6-96.714c-7.014-4.149-16.836-1.597-20.967 5.374l-10.869 18.36a15.2 15.2 0 0 0-1.658 11.591 15.21 15.21 0 0 0 7.031 9.363zM387.525 240.501a15.276 15.276 0 0 0 12.626 6.659c3.091 0 6.077-.924 8.635-2.681l17.405-11.934c6.953-4.768 8.752-14.314 4.015-21.292L323.29 54.104c-4.584-6.732-14.498-8.623-21.236-3.984l-17.737 12.21c-6.945 4.779-8.727 14.327-3.971 21.291l107.179 156.88zM154.482 302.319l183.465 49.156c1.298.349 2.632.526 3.966.526 6.903 0 12.98-4.67 14.762-11.347l5.508-20.624c2.179-8.152-2.681-16.555-10.826-18.74l-183.465-49.162c-8.017-2.148-16.604 2.852-18.728 10.826l-5.508 20.63c-2.179 8.142 2.68 16.551 10.826 18.735z"></path></svg>Stack Overflow</a></li>
</ul>
</div>
<div class="subscribe">
<a href="https://share.hsforms.com/1e2W03wLJQQKPd1d9rCbj_Q2npzm"><button class="btn btn-subscribe f-tc">Subscribe to Blog</button></a>
</div>
</div>
</div>
<div class="container copyright-container">
<p class="copyright">© 2020 PingCAP. All Rights Reserved.</p>
<a class="copyright-btn-lang" href="/blog-cn" id="lang">中文</a>
</div>
</footer>
<button class="back-to-top" type="button"><svg height="512" viewbox="0 0 284.929 284.929" width="512" xmlns="http://www.w3.org/2000/svg"><path d="M282.082 195.285L149.028 62.24c-1.901-1.903-4.088-2.856-6.562-2.856s-4.665.953-6.567 2.856L2.856 195.285C.95 197.191 0 199.378 0 201.853c0 2.474.953 4.664 2.856 6.566l14.272 14.271c1.903 1.903 4.093 2.854 6.567 2.854s4.664-.951 6.567-2.854l112.204-112.202 112.208 112.209c1.902 1.903 4.093 2.848 6.563 2.848 2.478 0 4.668-.951 6.57-2.848l14.274-14.277c1.902-1.902 2.847-4.093 2.847-6.566.001-2.476-.944-4.666-2.846-6.569z" fill="#FFF"></path></svg>
</button>
</div><div class="overlay"></div><script src="https://download.pingcap.com/js/jquery.min.js"></script><script src="/js/vendor/lazyload.min.js" type="text/javascript"></script>
<script src="/js/doc.js" type="text/javascript"></script>
<script src="/js/anchor.js" type="text/javascript"></script><script src="https://cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js"></script><script src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script crossorigin="anonymous" integrity="sha384-jbFinqIbKkHNg+QL+yxB4VrBC0EAPTuaLGeRT0T+NfEV89YC6u1bKxHLwoo+/xxY" src="https://browser.sentry-cdn.com/5.11.0/bundle.min.js"></script><script>Sentry.init({ 
            dsn: 'https://3f28ed393c5545daa74496b3cdb2e9ba@sentry.io/1887163' 
        });</script></body></html>